"""
æµ‹è¯•çˆ¬å–å™¨å¢å¼ºåŠŸèƒ½
æµ‹è¯•æ–°å¢çš„åˆ†ç±»ä¿¡æ¯ã€æŠ€æœ¯é¢†åŸŸã€åŒæ—ä¸“åˆ©ã€å¤–éƒ¨é“¾æ¥ç­‰åŠŸèƒ½
"""

import sys
import json
from backend.scraper.simple_scraper import SimplePatentScraper

def test_enhanced_scraper():
    """æµ‹è¯•å¢å¼ºçš„çˆ¬å–å™¨åŠŸèƒ½"""
    
    # æµ‹è¯•ä¸“åˆ©å·
    patent_number = "US12390907B2"
    
    print(f"\n{'='*80}")
    print(f"æµ‹è¯•ä¸“åˆ©: {patent_number}")
    print(f"{'='*80}\n")
    
    # åˆ›å»ºçˆ¬å–å™¨å®ä¾‹
    scraper = SimplePatentScraper(delay=1.0)
    
    # çˆ¬å–ä¸“åˆ©ï¼ˆåŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
    print("å¼€å§‹çˆ¬å–ä¸“åˆ©ä¿¡æ¯...")
    result = scraper.scrape_patent(
        patent_number=patent_number,
        crawl_specification=True,  # çˆ¬å–è¯´æ˜ä¹¦å’Œè¿›é˜¶ä¿¡æ¯
        crawl_full_drawings=False   # åªçˆ¬å–ç¬¬ä¸€å¼ é™„å›¾
    )
    
    if result.success:
        print(f"\nâœ… çˆ¬å–æˆåŠŸï¼å¤„ç†æ—¶é—´: {result.processing_time:.2f}ç§’\n")
        
        data = result.data
        
        # 1. åŸºç¡€ä¿¡æ¯
        print(f"{'='*80}")
        print("ğŸ“‹ åŸºç¡€ä¿¡æ¯")
        print(f"{'='*80}")
        print(f"ä¸“åˆ©å·: {data.patent_number}")
        print(f"æ ‡é¢˜: {data.title}")
        print(f"æ‘˜è¦: {data.abstract[:100]}..." if len(data.abstract) > 100 else f"æ‘˜è¦: {data.abstract}")
        print(f"å‘æ˜äºº: {', '.join(data.inventors)}")
        print(f"ç”³è¯·äºº: {', '.join(data.assignees)}")
        print(f"ä¼˜å…ˆæƒæ—¥æœŸ: {data.priority_date}")
        print(f"ç”³è¯·æ—¥æœŸ: {data.application_date}")
        print(f"å…¬å¼€æ—¥æœŸ: {data.publication_date}")
        
        # 2. CPCåˆ†ç±»ä¿¡æ¯
        print(f"\n{'='*80}")
        print(f"ğŸ“Š CPCåˆ†ç±»ä¿¡æ¯ (å…± {len(data.classifications)} æ¡)")
        print(f"{'='*80}")
        for i, cls in enumerate(data.classifications[:5], 1):  # åªæ˜¾ç¤ºå‰5æ¡
            print(f"\n{i}. {cls['leaf_code']}")
            print(f"   å®Œæ•´è·¯å¾„: {cls['code']}")
            print(f"   æè¿°: {cls['leaf_description']}")
            print(f"   æ˜¯å¦CPC: {cls['is_cpc']}")
            print(f"   æ˜¯å¦å¶å­èŠ‚ç‚¹: {cls['is_leaf']}")
        
        if len(data.classifications) > 5:
            print(f"\n... è¿˜æœ‰ {len(data.classifications) - 5} æ¡åˆ†ç±»ä¿¡æ¯")
        
        # 3. æŠ€æœ¯é¢†åŸŸ
        print(f"\n{'='*80}")
        print(f"ğŸŒ æŠ€æœ¯é¢†åŸŸ (å…± {len(data.landscapes)} æ¡)")
        print(f"{'='*80}")
        for i, landscape in enumerate(data.landscapes, 1):
            print(f"{i}. {landscape['name']} ({landscape['type']})")
        
        # 4. å¤–éƒ¨é“¾æ¥
        print(f"\n{'='*80}")
        print(f"ğŸ”— å¤–éƒ¨é“¾æ¥ (å…± {len(data.external_links)} ä¸ª)")
        print(f"{'='*80}")
        for link_id, link_info in data.external_links.items():
            print(f"â€¢ {link_info['text']}: {link_info['url']}")
        
        # 5. åŒæ—ä¿¡æ¯
        print(f"\n{'='*80}")
        print(f"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ åŒæ—ä¿¡æ¯")
        print(f"{'='*80}")
        print(f"åŒæ—ID: {data.family_id}")
        
        print(f"\nåŒæ—ç”³è¯· (å…± {len(data.family_applications)} ä¸ª):")
        for i, app in enumerate(data.family_applications, 1):
            print(f"\n{i}. {app['application_number']}")
            print(f"   çŠ¶æ€: {app['status']}")
            print(f"   å…¬å¼€å·: {app['publication_number']} ({app['language']})")
            print(f"   ç”³è¯·æ—¥æœŸ: {app['filing_date']}")
            print(f"   æ ‡é¢˜: {app['title'][:50]}..." if len(app['title']) > 50 else f"   æ ‡é¢˜: {app['title']}")
            if app['expiration']:
                print(f"   åˆ°æœŸæ—¥: {app['expiration']}")
        
        print(f"\nå›½å®¶çŠ¶æ€ (å…± {len(data.country_status)} ä¸ªå›½å®¶/åœ°åŒº):")
        for i, country in enumerate(data.country_status, 1):
            print(f"{i}. {country['country_code']} - {country['count']} ä¸ªç”³è¯·")
            print(f"   ä»£è¡¨æ€§å…¬å¼€: {country['publication_number']} ({country['language']})")
            if country['is_this_country']:
                print(f"   â­ å½“å‰å›½å®¶")
        
        # 6. å¼•ç”¨ä¿¡æ¯
        print(f"\n{'='*80}")
        print(f"ğŸ“š å¼•ç”¨ä¿¡æ¯")
        print(f"{'='*80}")
        print(f"å¼•ç”¨çš„ä¸“åˆ©: {len(data.patent_citations)} æ¡")
        print(f"è¢«å¼•ç”¨çš„ä¸“åˆ©: {len(data.cited_by)} æ¡")
        
        if data.cited_by:
            print(f"\nè¢«å¼•ç”¨ä¸“åˆ©ç¤ºä¾‹ (å‰3æ¡):")
            for i, citation in enumerate(data.cited_by[:3], 1):
                print(f"\n{i}. {citation['patent_number']}")
                print(f"   æ ‡é¢˜: {citation['title'][:50]}..." if len(citation['title']) > 50 else f"   æ ‡é¢˜: {citation['title']}")
                print(f"   ç”³è¯·äºº: {citation['assignee']}")
                print(f"   å…¬å¼€æ—¥æœŸ: {citation['publication_date']}")
                if citation['examiner_cited']:
                    print(f"   â­ å®¡æŸ¥å‘˜å¼•ç”¨")
        
        # 7. å…¶ä»–ä¿¡æ¯
        print(f"\n{'='*80}")
        print(f"ğŸ“ å…¶ä»–ä¿¡æ¯")
        print(f"{'='*80}")
        print(f"æƒåˆ©è¦æ±‚: {len(data.claims)} æ¡")
        print(f"é™„å›¾: {len(data.drawings)} å¼ ")
        print(f"æ³•å¾‹äº‹ä»¶: {len(data.legal_events)} ä¸ª")
        print(f"ç›¸ä¼¼æ–‡æ¡£: {len(data.similar_documents)} ä¸ª")
        
        # ä¿å­˜å®Œæ•´æ•°æ®åˆ°JSONæ–‡ä»¶
        output_file = f"test_output_{patent_number.replace('/', '_')}_enhanced.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result.to_dict(), f, ensure_ascii=False, indent=2)
        
        print(f"\n{'='*80}")
        print(f"âœ… å®Œæ•´æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        print(f"{'='*80}\n")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*80}")
        print(f"ğŸ“Š æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡")
        print(f"{'='*80}")
        
        fields = {
            'åŸºç¡€ä¿¡æ¯': bool(data.title and data.abstract),
            'CPCåˆ†ç±»': len(data.classifications) > 0,
            'æŠ€æœ¯é¢†åŸŸ': len(data.landscapes) > 0,
            'å¤–éƒ¨é“¾æ¥': len(data.external_links) > 0,
            'åŒæ—ID': bool(data.family_id),
            'åŒæ—ç”³è¯·': len(data.family_applications) > 0,
            'å›½å®¶çŠ¶æ€': len(data.country_status) > 0,
            'ä¼˜å…ˆæƒæ—¥æœŸ': bool(data.priority_date),
            'å¼•ç”¨ä¸“åˆ©': len(data.patent_citations) > 0,
            'è¢«å¼•ç”¨ä¸“åˆ©': len(data.cited_by) > 0,
            'æƒåˆ©è¦æ±‚': len(data.claims) > 0,
            'é™„å›¾': len(data.drawings) > 0,
            'æ³•å¾‹äº‹ä»¶': len(data.legal_events) > 0,
        }
        
        total_fields = len(fields)
        completed_fields = sum(1 for v in fields.values() if v)
        
        for field, status in fields.items():
            status_icon = "âœ…" if status else "âŒ"
            print(f"{status_icon} {field}")
        
        print(f"\nå®Œæ•´åº¦: {completed_fields}/{total_fields} ({completed_fields/total_fields*100:.1f}%)")
        
    else:
        print(f"\nâŒ çˆ¬å–å¤±è´¥: {result.error}")
    
    # å…³é—­çˆ¬å–å™¨
    scraper.close()


if __name__ == "__main__":
    test_enhanced_scraper()
