## 阿里云百炼集成计划（与智谱AI并行）

### 设计原则
- **并行而非取代**：保留智谱AI作为默认服务商
- **用户可选**：提供服务商切换选项
- **最小改动**：尽量复用现有代码结构
- **向后兼容**：不影响现有功能

---

### 第一阶段：后端服务层改造

#### 1.1 创建统一LLM客户端服务
**文件**: `backend/services/llm_service.py`（新建）

```python
def get_llm_client(provider='zhipu'):
    """统一获取LLM客户端"""
    if provider == 'aliyun':
        return OpenAI(api_key=..., base_url=ALIYUN_BASE_URL)
    else:
        return ZhipuAI(api_key=...)
```

#### 1.2 修改现有路由
**文件**: `backend/routes/chat.py`

- 添加 `provider` 参数支持
- 阿里云响应格式适配（处理 `reasoning_content`）
- 保持智谱AI原有逻辑不变

---

### 第二阶段：前端改造

#### 2.1 状态管理
**文件**: `js/state.js`

```javascript
appState = {
    provider: 'zhipu',  // 新增：当前服务商
    aliyunApiKey: '',   // 新增：阿里云API Key
    // ... 其他状态保持不变
}
```

#### 2.2 API配置UI
**文件**: `js/core/api.js` 或新建 `js/core/provider.js`

- 添加服务商切换下拉框
- 添加阿里云API Key输入框
- 根据服务商动态切换模型列表

#### 2.3 模型列表更新
**文件**: `config/models.json`

```json
{
  "zhipu": ["glm-4-flash", "glm-4.7-flash", ...],
  "aliyun": ["qwen-plus", "qwen-turbo", "deepseek-v3.2", ...]
}
```

---

### 第三阶段：功能适配

#### 3.1 流式调用适配
- 阿里云思考模式响应包含 `reasoning_content` 字段
- 前端需要处理并显示思考过程

#### 3.2 联网搜索适配
- 智谱：使用 `tools` 参数
- 阿里云：使用 `extra_body.enable_search`

#### 3.3 批量处理适配
- 两家都支持Batch API，格式略有不同

---

### 执行步骤

1. **后端服务层**：创建统一客户端获取函数
2. **后端路由**：修改chat.py支持provider参数
3. **前端状态**：添加provider和aliyunApiKey
4. **前端UI**：添加服务商切换界面
5. **模型配置**：更新模型列表
6. **测试验证**：确保两家服务商都能正常工作

---

### 风险控制

- 默认服务商为智谱AI，不影响现有用户
- 阿里云API Key独立存储，不与智谱混淆
- 前端会检测当前服务商，动态显示对应模型