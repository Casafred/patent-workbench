# 权利要求处理性能优化方案

## 当前问题

### 1. 轮询频率过高
- 每1秒轮询一次任务状态
- 对于大文件处理（几分钟），产生大量无用请求
- 控制台日志刷屏，影响调试

### 2. 处理速度慢
- 1000行数据处理时间过长（几分钟）
- 用户体验差，不知道实际进度

### 3. 架构问题
- 逐行串行处理，没有并行优化
- 进度更新不及时（0% → 100%）
- 每10行保存状态，有IO开销

## 优化方案

### 短期优化（立即可实施）

#### 1. 调整轮询策略
```javascript
// 当前：固定1秒
setInterval(pollStatus, 1000);

// 优化：渐进式轮询
// 前30秒：每2秒轮询一次
// 30秒-2分钟：每5秒轮询一次
// 2分钟后：每10秒轮询一次
```

**优点**：
- 减少90%的无用请求
- 控制台更清爽
- 降低服务器负载

#### 2. 添加实时进度更新
```python
# 在处理循环中更新进度
for i, cell_text in enumerate(column_data):
    # 处理逻辑...
    
    # 每处理10行更新一次进度
    if i % 10 == 0:
        progress = int((i / len(column_data)) * 100)
        processing_tasks[task_id]['progress'] = progress
```

**优点**：
- 用户能看到实时进度
- 知道系统在工作，不会误以为卡死

#### 3. 减少状态保存频率
```python
# 当前：每10行保存一次
if i % 10 == 0:
    self._save_processing_state(...)

# 优化：每100行或每10%保存一次
save_interval = max(100, len(column_data) // 10)
if i % save_interval == 0:
    self._save_processing_state(...)
```

**优点**：
- 减少磁盘IO
- 提升处理速度10-20%

### 中期优化（需要重构）

#### 4. 批量处理优化
```python
# 当前：逐行处理
for cell_text in column_data:
    detect_language(cell_text)  # 每次调用
    parse_claims(cell_text)     # 每次调用

# 优化：批量处理
batch_size = 50
for i in range(0, len(column_data), batch_size):
    batch = column_data[i:i+batch_size]
    languages = detect_language_batch(batch)  # 批量检测
    claims = parse_claims_batch(batch)        # 批量解析
```

**优点**：
- 减少函数调用开销
- 可以利用向量化操作
- 预计提升速度30-50%

#### 5. 多线程/多进程处理
```python
from concurrent.futures import ThreadPoolExecutor

def process_batch(batch_data):
    # 处理一批数据
    return results

# 将数据分成多个批次并行处理
with ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(process_batch, batch) 
               for batch in batches]
    results = [f.result() for f in futures]
```

**优点**：
- 充分利用多核CPU
- 预计提升速度2-4倍（取决于CPU核心数）

**注意**：
- 需要处理线程安全问题
- 进度更新需要加锁

### 长期优化（架构升级）

#### 6. 使用任务队列（Celery + Redis）
```python
# 异步任务处理
@celery.task(bind=True)
def process_claims_async(self, file_path, column_name):
    for i, cell in enumerate(data):
        # 处理...
        # 更新进度到Redis
        self.update_state(
            state='PROGRESS',
            meta={'current': i, 'total': len(data)}
        )
```

**优点**：
- 真正的异步处理
- 可以分布式部署
- 支持任务优先级、重试等
- 进度更新更可靠

#### 7. WebSocket实时推送
```javascript
// 前端
const ws = new WebSocket('ws://server/claims/progress');
ws.onmessage = (event) => {
    const progress = JSON.parse(event.data);
    updateProgress(progress);
};

// 后端
async def send_progress(task_id, progress):
    await websocket.send(json.dumps({
        'task_id': task_id,
        'progress': progress
    }))
```

**优点**：
- 实时推送，无需轮询
- 减少99%的HTTP请求
- 更好的用户体验

#### 8. 缓存和预处理
```python
# 缓存语言检测结果
@lru_cache(maxsize=1000)
def detect_language(text_hash):
    # 检测逻辑
    
# 预编译正则表达式
CLAIM_PATTERNS = {
    'zh': re.compile(r'权利要求\s*(\d+)', re.IGNORECASE),
    'en': re.compile(r'claim\s*(\d+)', re.IGNORECASE),
    # ...
}
```

**优点**：
- 避免重复计算
- 减少正则编译开销
- 提升速度10-20%

## 推荐实施顺序

### 第一阶段（本周）- 快速见效
1. ✅ 调整轮询策略（渐进式轮询）
2. ✅ 添加实时进度更新
3. ✅ 减少状态保存频率

**预期效果**：
- 处理速度提升15-25%
- 用户体验明显改善
- 服务器负载降低

### 第二阶段（下周）- 性能提升
4. 批量处理优化
5. 正则表达式缓存

**预期效果**：
- 处理速度再提升30-40%
- 总体提升约50-60%

### 第三阶段（未来）- 架构升级
6. 多线程处理（如果单机部署）
7. 任务队列 + WebSocket（如果需要分布式）

**预期效果**：
- 处理速度提升2-4倍
- 支持更大规模数据
- 更好的可扩展性

## 性能基准测试

### 当前性能（未优化）
- 100行：~10秒
- 500行：~50秒
- 1000行：~100秒（1分40秒）

### 目标性能（第一阶段后）
- 100行：~8秒（提升20%）
- 500行：~40秒（提升20%）
- 1000行：~80秒（提升20%）

### 目标性能（第二阶段后）
- 100行：~5秒（提升50%）
- 500行：~25秒（提升50%）
- 1000行：~50秒（提升50%）

### 目标性能（第三阶段后）
- 100行：~2秒（提升80%）
- 500行：~10秒（提升80%）
- 1000行：~20秒（提升80%）

## 实施建议

1. **先实施第一阶段**：快速见效，风险低
2. **测量实际效果**：使用真实数据测试
3. **根据需求决定**：是否需要第二、三阶段
4. **考虑成本**：第三阶段需要Redis等额外服务

## 结论

**当前速度慢的主要原因是架构问题，不是服务器性能问题**：
- 轮询策略不合理
- 缺少进度反馈
- 串行处理没有优化

通过第一阶段的简单优化，就能获得明显的性能提升和用户体验改善。
